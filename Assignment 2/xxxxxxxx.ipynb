{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Business Analytics - Assignment 2  \n",
    "\n",
    "**Assignment Points**: 100  \n",
    "**Submission**: Provide your answers in this notebook and submit it via iLearn\n",
    "\n",
    "- Where a question requires a written (text) solution provide your answer in Markdown in appropriate cells under each question.\n",
    "- Comment out your print statements unless you are explicitly asked to use the print() function. \n",
    "- 5 marks will be deducted for printed outputs that are not asked for."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### About the Assignment\n",
    "\n",
    "- Assignment 2 extends Assignment 1 on credit card applications. \n",
    "\n",
    "\n",
    "- For this assignment there are two files in the `data` folder `credit_record.csv` and `application_record.csv` where bank clients are related by the `ID` column.\n",
    "- In `credit_record.csv` we have the following variables\n",
    "\n",
    "| Feature Name         | Explanation     | Additional Remarks |\n",
    "|--------------|-----------|-----------|\n",
    "| ID | Randomly allocated client number      |         |\n",
    "| AMT_INCOME_TOTAL   | Annual income  |  |\n",
    "| NAME_INCOME_TYPE   | Income Source |  |\n",
    "| NAME_EDUCATION_TYPE   | Level of Education  |  |\n",
    "| CODE_GENDER   | Applicant's Gender   |  |\n",
    "| FLAG_OWN_CAR | Car Ownership |  | \n",
    "| CNT_CHILDREN | Number of Children | |\n",
    "| FLAG_OWN_REALTY | Real Estate Ownership | | \n",
    "| NAME_FAMILY_STATUS | Relationship Status | | \n",
    "| NAME_HOUSING_TYPE | Housing Type | | \n",
    "| DAYS_BIRTH | No. of Days | Count backwards from current day (0), -1 means yesterday\n",
    "| DAYS_EMPLOYED | No. of Days | Count backwards from current day(0). If positive, it means the person is currently unemployed.\n",
    "| FLAG_MOBIL | Mobile Phone Ownership | | \n",
    "| FLAG_WORK_PHONE | Work Phone Ownership | | \n",
    "| FLAG_PHONE | Landline Phone Ownership | | \n",
    "| FLAG_EMAIL | Landline Phone Ownership | | \n",
    "| OCCUPATION_TYPE | Occupation | | \n",
    "| CNT_FAM_MEMBERS | Count of Family Members | |\n",
    "\n",
    "\n",
    "\n",
    "- In `credit_record.csv` we have the following variables\n",
    "\n",
    "\n",
    "| Feature Name         | Explanation     | Additional Remarks |\n",
    "|--------------|-----------|-----------|\n",
    "| ID | Randomly allocated client number | |\n",
    "| MONTHS_BALANCE | Number of months in the past from now when STATUS is measured | 0 = current month, -1 = last month, -2 = two months ago, etc.|\n",
    "| STATUS | Number of days a payment is past due | 0: 1-29 days past due 1: 30-59 days past due 2: 60-89 days overdue 3: 90-119 days overdue 4: 120-149 days overdue 5: Overdue or bad debts, write-offs for more than 150 days C: paid off that month X: No loan for the month |"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "---\n",
    "\n",
    "### Task 1: Reading, Summarising and Cleaning Data (Total Marks: 30)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "\n",
    "**Question 1.** \n",
    "\n",
    "1. Import the `application_record.csv` and `credit_record.csv` files from `data` folder into pandas DataFrames named `df_application` and `df_credit`, respectively. (1 mark)\n",
    "\n",
    "2. How many rows are there in `df_application` and `df_credit`, respectively? Answer using both print() function and in Markdown text. (1 mark)\n",
    "\n",
    "3. How many unique bank clients are there in `df_application` and `df_credit`? Answer using both print() function and in Markdown text. (1 mark)\n",
    "\n",
    "4. Add the records from `df_credit` to `df_application` by merging the data from the two DataFrames on the `ID` column, and output the joint data into a new DataFrame named `df`. Hint: Use `merge` function from pandas by setting `how` parameter to `inner` (4 marks) \n",
    "\n",
    "5. How many rows and how many unique clients are there in `df`? (1 mark)\n",
    "\n",
    "6. How are multiple rows for each `ID` in `df` different? Answer in Markdown text. (2 mark) \n",
    "\n",
    "(10 marks)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "from io import StringIO # allows us to read from a string as if we are reading from a file\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn import datasets\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.discriminant_analysis import LinearDiscriminantAnalysis as LDA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "There are 438557 rows in df_application\n",
      "There are 1048575 rows in df_credit\n",
      "There are 438510 unique bank clients in df_application\n",
      "There are 45985 unique bank clients in df_credit\n",
      "There are 36457 rows and 36457 unique clients in df\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "df_application = pd.read_csv('data/application_record.csv')\n",
    "df_credit = pd.read_csv('data/credit_record.csv')\n",
    "print(f'There are {len(df_application)} rows in df_application')\n",
    "print(f'There are {len(df_credit)} rows in df_credit')\n",
    "df_application = df_application.drop_duplicates(subset=['ID'])\n",
    "y = df_credit['ID'].unique()\n",
    "print(f'There are {len(df_application)} unique bank clients in df_application')\n",
    "print(f'There are {len(y)} unique bank clients in df_credit')\n",
    "df = pd.merge(df_application,df_credit, how='inner')\n",
    "df\n",
    "F = len(df['ID'].unique())\n",
    "print(f'There are {F} rows and {F} unique clients in df')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---- provide your text answer here ----\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "**Question 2.**\n",
    "\n",
    "1. Change the values of `STATUS` in `df` according to the following mapping: {C, X, 0} -> 0 and {1, 2, 3, 4, 5} -> 1 making sure that the new values of 0 and 1 are encoded as integers. (2 marks)\n",
    "2. Create a new numpy array named `list_of_defaults` containing *unique* `ID` numbers for the clients who have `STATUS` = 1 in any of the last 12 months in the dataset. (2 marks) \n",
    "3. Create a new DataFrame called `df_final` that contains the rows of `df` for which the `ID` are in `list_of_defaults`, keeping only one row for each `ID` (i.e. eliminate rows with duplicate `ID`s while keeping the first duplicate row). How many rows do you have in `df_final`? Answer using both print() function and in Markdown text. (Hint: find out about `isin()` function in pandas.) (2 marks)\n",
    "4. Add a new column `y = 1` for all the rows in `df_final`. (1 marks)\n",
    "5. Increase `df_final` to a total of 4,000 rows by adding rows from `df` with unique `ID`s (nonduplicated `ID`s) which are not in `list_of_defaults`. To do this start adding the rows from the beginning of `df`. (Hint: learn what `~`, i.e. tilde sign, does in pandas). (2 marks) \n",
    "6. Fill the missing values of `y` in `df_final` with zeros. Remove `STATUS` and `MONTHS_BALANCE` from `df_final`. How many clients with  overdue payments of more than 29 days and how many clients with less than 29 days overdue payments are there in `df_final`? Answer using both print() function and in Markdown text.(1 mark)\n",
    "\n",
    "(10 marks)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "THERE ARE 0 THAT ARE 30-59 days AND LIKE ANOTHER 2167 THAT ARE 0-29 days\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "size_mapping = {'C':0, 'X':0, '0':0, '1':1, '2':1, '3':1, '4':1, '5':1}\n",
    "\n",
    "df['STATUS'] = df['STATUS'].map(size_mapping)\n",
    "\n",
    "MonthsOnly = df.loc[df['MONTHS_BALANCE'].isin(np.arange(-12,1,1))]# we locate the rows where MONTHS_BALANCE is between 0 and -12\n",
    "MonthsOnly = MonthsOnly.query(f\"STATUS =={1}\")#Remove any status that isnt 1\n",
    "list_of_defaults = MonthsOnly['ID'].unique()#Take only unique ID's\n",
    "df_final = MonthsOnly.drop_duplicates('ID')\n",
    "\n",
    "Length_change = 3999-len(df_final)\n",
    "y = []\n",
    "for i in range(len(df_final)):\n",
    "    y.append(1)\n",
    "df_final['y'] = y\n",
    "\n",
    "df_final = pd.concat([df_final,((df.loc[~df['ID'].isin(list(list_of_defaults))].drop_duplicates(\"ID\").reset_index()).drop('index',axis=1)).loc[0:LENGTHBOI,:]])\n",
    "#Okay so, this is the combination of df_final and the rows of the IDs not in the list of list_of_defaults. We then reset the index, drop the old index, take the first N rows and thats all folks!\n",
    "\n",
    "df_final['y'] = df_final['y'].fillna(0)\n",
    "\n",
    "df_final=df_final.drop(['STATUS','MONTHS_BALANCE'],axis=1)\n",
    "print(f'THERE ARE {len(df_final.query(f\"y =={float(1)}\"))} THAT ARE 30-59 days AND LIKE ANOTHER {len(df_final.query(f\"y =={float(0)}\"))} THAT ARE 0-29 days')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---- provide your text answer here ----\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<hr style=\"width:25%;margin-left:0;\"> \n",
    "\n",
    "**Question 3**. \n",
    "- Delete `ID` column from `df_final` (1 marks)\n",
    "- Of the remaining variables in `df_final` and assuming that `NAME_EDUCATION_TYPE` is the only ordinal variable, how many variable are of numeric and nominal types? Provide lists of all numeric and nominal variables. (6)\n",
    "- Using an appropriate function find and comment on the missing values in `df_final`, i.e. how many variables and how many observations? (3 marks)   \n",
    "(10 marks)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_final.drop('ID', inplace=True, axis=1)\n",
    "df_final.head()\n",
    "#add to the box below "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The numeric values are ['CNT_CHILDREN', 'AMT_INCOME_TOTAL', 'DAYS_BIRTH', 'DAYS_EMPLOYED', 'FLAG_MOBIL', 'FLAG_WORK_PHONE', 'FLAG_PHONE', 'FLAG_EMAIL', 'OCCUPATION_TYPE', 'CNT_FAM_MEMBERS', 'y'] and there are 11 of them.\n",
      "The nominal values are ['CODE_GENDER', 'FLAG_OWN_CAR', 'FLAG_OWN_REALTY', 'NAME_INCOME_TYPE', 'NAME_FAMILY_STATUS', 'NAME_HOUSING_TYPE'] and there are 6 of them.\n",
      "CODE_GENDER, 0\n",
      "FLAG_OWN_CAR, 0\n",
      "FLAG_OWN_REALTY, 0\n",
      "CNT_CHILDREN, 74\n",
      "AMT_INCOME_TOTAL, 0\n",
      "NAME_INCOME_TYPE, 0\n",
      "NAME_EDUCATION_TYPE, 1831\n",
      "NAME_FAMILY_STATUS, 0\n",
      "NAME_HOUSING_TYPE, 0\n",
      "DAYS_BIRTH, 0\n",
      "DAYS_EMPLOYED, 0\n",
      "FLAG_MOBIL, 0\n",
      "FLAG_WORK_PHONE, 0\n",
      "FLAG_PHONE, 0\n",
      "FLAG_EMAIL, 0\n",
      "OCCUPATION_TYPE, 648\n",
      "CNT_FAM_MEMBERS, 0\n",
      "y, 0\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>CODE_GENDER</th>\n",
       "      <th>FLAG_OWN_CAR</th>\n",
       "      <th>FLAG_OWN_REALTY</th>\n",
       "      <th>CNT_CHILDREN</th>\n",
       "      <th>AMT_INCOME_TOTAL</th>\n",
       "      <th>NAME_INCOME_TYPE</th>\n",
       "      <th>NAME_EDUCATION_TYPE</th>\n",
       "      <th>NAME_FAMILY_STATUS</th>\n",
       "      <th>NAME_HOUSING_TYPE</th>\n",
       "      <th>DAYS_BIRTH</th>\n",
       "      <th>DAYS_EMPLOYED</th>\n",
       "      <th>FLAG_MOBIL</th>\n",
       "      <th>FLAG_WORK_PHONE</th>\n",
       "      <th>FLAG_PHONE</th>\n",
       "      <th>FLAG_EMAIL</th>\n",
       "      <th>OCCUPATION_TYPE</th>\n",
       "      <th>CNT_FAM_MEMBERS</th>\n",
       "      <th>y</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>M</td>\n",
       "      <td>Y</td>\n",
       "      <td>Y</td>\n",
       "      <td>0.0</td>\n",
       "      <td>427500.0</td>\n",
       "      <td>Working</td>\n",
       "      <td>Higher education</td>\n",
       "      <td>Civil marriage</td>\n",
       "      <td>Rented apartment</td>\n",
       "      <td>-12005</td>\n",
       "      <td>-4542</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>M</td>\n",
       "      <td>Y</td>\n",
       "      <td>Y</td>\n",
       "      <td>0.0</td>\n",
       "      <td>427500.0</td>\n",
       "      <td>Working</td>\n",
       "      <td>Higher education</td>\n",
       "      <td>Civil marriage</td>\n",
       "      <td>Rented apartment</td>\n",
       "      <td>-12005</td>\n",
       "      <td>-4542</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>F</td>\n",
       "      <td>N</td>\n",
       "      <td>Y</td>\n",
       "      <td>0.0</td>\n",
       "      <td>283500.0</td>\n",
       "      <td>Pensioner</td>\n",
       "      <td>Higher education</td>\n",
       "      <td>Separated</td>\n",
       "      <td>House / apartment</td>\n",
       "      <td>-22464</td>\n",
       "      <td>365243</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>F</td>\n",
       "      <td>N</td>\n",
       "      <td>Y</td>\n",
       "      <td>0.0</td>\n",
       "      <td>283500.0</td>\n",
       "      <td>Pensioner</td>\n",
       "      <td>Higher education</td>\n",
       "      <td>Separated</td>\n",
       "      <td>House / apartment</td>\n",
       "      <td>-22464</td>\n",
       "      <td>365243</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>F</td>\n",
       "      <td>N</td>\n",
       "      <td>Y</td>\n",
       "      <td>0.0</td>\n",
       "      <td>283500.0</td>\n",
       "      <td>Pensioner</td>\n",
       "      <td>Higher education</td>\n",
       "      <td>Separated</td>\n",
       "      <td>House / apartment</td>\n",
       "      <td>-22464</td>\n",
       "      <td>365243</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2156</th>\n",
       "      <td>F</td>\n",
       "      <td>Y</td>\n",
       "      <td>N</td>\n",
       "      <td>1.0</td>\n",
       "      <td>306000.0</td>\n",
       "      <td>Working</td>\n",
       "      <td>Higher education</td>\n",
       "      <td>Married</td>\n",
       "      <td>House / apartment</td>\n",
       "      <td>-9310</td>\n",
       "      <td>-1678</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>3</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2157</th>\n",
       "      <td>F</td>\n",
       "      <td>Y</td>\n",
       "      <td>N</td>\n",
       "      <td>1.0</td>\n",
       "      <td>306000.0</td>\n",
       "      <td>Working</td>\n",
       "      <td>Higher education</td>\n",
       "      <td>Married</td>\n",
       "      <td>House / apartment</td>\n",
       "      <td>-9310</td>\n",
       "      <td>-1678</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>3</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2158</th>\n",
       "      <td>F</td>\n",
       "      <td>Y</td>\n",
       "      <td>N</td>\n",
       "      <td>1.0</td>\n",
       "      <td>306000.0</td>\n",
       "      <td>Working</td>\n",
       "      <td>Higher education</td>\n",
       "      <td>Married</td>\n",
       "      <td>House / apartment</td>\n",
       "      <td>-9310</td>\n",
       "      <td>-1678</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>3</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2159</th>\n",
       "      <td>F</td>\n",
       "      <td>Y</td>\n",
       "      <td>N</td>\n",
       "      <td>1.0</td>\n",
       "      <td>306000.0</td>\n",
       "      <td>Working</td>\n",
       "      <td>Higher education</td>\n",
       "      <td>Married</td>\n",
       "      <td>House / apartment</td>\n",
       "      <td>-9310</td>\n",
       "      <td>-1678</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>3</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2160</th>\n",
       "      <td>F</td>\n",
       "      <td>Y</td>\n",
       "      <td>N</td>\n",
       "      <td>1.0</td>\n",
       "      <td>306000.0</td>\n",
       "      <td>Working</td>\n",
       "      <td>Higher education</td>\n",
       "      <td>Married</td>\n",
       "      <td>House / apartment</td>\n",
       "      <td>-9310</td>\n",
       "      <td>-1678</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>3</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1945 rows Ã— 18 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     CODE_GENDER FLAG_OWN_CAR FLAG_OWN_REALTY  CNT_CHILDREN  AMT_INCOME_TOTAL  \\\n",
       "0              M            Y               Y           0.0          427500.0   \n",
       "1              M            Y               Y           0.0          427500.0   \n",
       "7              F            N               Y           0.0          283500.0   \n",
       "8              F            N               Y           0.0          283500.0   \n",
       "9              F            N               Y           0.0          283500.0   \n",
       "...          ...          ...             ...           ...               ...   \n",
       "2156           F            Y               N           1.0          306000.0   \n",
       "2157           F            Y               N           1.0          306000.0   \n",
       "2158           F            Y               N           1.0          306000.0   \n",
       "2159           F            Y               N           1.0          306000.0   \n",
       "2160           F            Y               N           1.0          306000.0   \n",
       "\n",
       "     NAME_INCOME_TYPE NAME_EDUCATION_TYPE NAME_FAMILY_STATUS  \\\n",
       "0             Working    Higher education     Civil marriage   \n",
       "1             Working    Higher education     Civil marriage   \n",
       "7           Pensioner    Higher education          Separated   \n",
       "8           Pensioner    Higher education          Separated   \n",
       "9           Pensioner    Higher education          Separated   \n",
       "...               ...                 ...                ...   \n",
       "2156          Working    Higher education            Married   \n",
       "2157          Working    Higher education            Married   \n",
       "2158          Working    Higher education            Married   \n",
       "2159          Working    Higher education            Married   \n",
       "2160          Working    Higher education            Married   \n",
       "\n",
       "      NAME_HOUSING_TYPE  DAYS_BIRTH  DAYS_EMPLOYED  FLAG_MOBIL  \\\n",
       "0      Rented apartment      -12005          -4542           1   \n",
       "1      Rented apartment      -12005          -4542           1   \n",
       "7     House / apartment      -22464         365243           1   \n",
       "8     House / apartment      -22464         365243           1   \n",
       "9     House / apartment      -22464         365243           1   \n",
       "...                 ...         ...            ...         ...   \n",
       "2156  House / apartment       -9310          -1678           1   \n",
       "2157  House / apartment       -9310          -1678           1   \n",
       "2158  House / apartment       -9310          -1678           1   \n",
       "2159  House / apartment       -9310          -1678           1   \n",
       "2160  House / apartment       -9310          -1678           1   \n",
       "\n",
       "      FLAG_WORK_PHONE  FLAG_PHONE  FLAG_EMAIL OCCUPATION_TYPE  \\\n",
       "0                   1           0           0             NaN   \n",
       "1                   1           0           0             NaN   \n",
       "7                   0           0           0             NaN   \n",
       "8                   0           0           0             NaN   \n",
       "9                   0           0           0             NaN   \n",
       "...               ...         ...         ...             ...   \n",
       "2156                0           0           0             NaN   \n",
       "2157                0           0           0             NaN   \n",
       "2158                0           0           0             NaN   \n",
       "2159                0           0           0             NaN   \n",
       "2160                0           0           0             NaN   \n",
       "\n",
       "      CNT_FAM_MEMBERS    y  \n",
       "0                   2  0.0  \n",
       "1                   2  0.0  \n",
       "7                   1  0.0  \n",
       "8                   1  0.0  \n",
       "9                   1  0.0  \n",
       "...               ...  ...  \n",
       "2156                3  0.0  \n",
       "2157                3  0.0  \n",
       "2158                3  0.0  \n",
       "2159                3  0.0  \n",
       "2160                3  0.0  \n",
       "\n",
       "[1945 rows x 18 columns]"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "Nominal = []\n",
    "Numeric = []\n",
    "for columns in df_final:\n",
    "    if columns == 'NAME_EDUCATION_TYPE': \n",
    "        continue\n",
    "    elif str(type(df_final[columns][0])) == \"<class 'str'>\":\n",
    "        Nominal.append(columns)\n",
    "    else:\n",
    "        Numeric.append(columns)\n",
    "print(f'The numeric values are {Numeric} and there are {len(Numeric)} of them.')\n",
    "print(f'The nominal values are {Nominal} and there are {len(Nominal)} of them.')\n",
    "\n",
    "for columns in df_final:\n",
    "    print(f\"{columns}, {len(df_final[df_final[f'{columns}'].isna()])}\")# Finds NaN in columns\n",
    "\n",
    "df_final[df_final.isna().any(axis=1)]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---- provide your text answer here ----"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "---\n",
    "\n",
    "### Task 2: Imputing missing values and dealing with categorical features (Total Marks: 30)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Question 4.** \n",
    "- Use an appropriate `pandas` function to impute missing values in `df_final` (10 marks)\n",
    "    - Be careful when deciding which method to use to replace missing observations \n",
    "    - Take into consideration the type of each variable and the best practices we discussed in class/lecture notes\n",
    "- Briefly explain what you have done and why. (5 marks)\n",
    "\n",
    "(Total: 15 marks)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CNT_CHILDREN             0.394804\n",
      "AMT_INCOME_TOTAL    198126.524250\n",
      "DAYS_BIRTH          -15850.792000\n",
      "DAYS_EMPLOYED        55639.906750\n",
      "FLAG_MOBIL               1.000000\n",
      "FLAG_WORK_PHONE          0.215500\n",
      "FLAG_PHONE               0.306750\n",
      "FLAG_EMAIL               0.140500\n",
      "CNT_FAM_MEMBERS          2.187250\n",
      "y                        0.458250\n",
      "dtype: float64\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "print(df_final.mean(axis=0)) \n",
    "print(df_final.fillna(df_final.mean(axis = 0), inplace=True))  #fill NaN with column mean values\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---- provide your text answer here ----\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<hr style=\"width:25%;margin-left:0;\"> \n",
    "\n",
    "**Question 5**. Convert the values in `NAME_EDUCATION_TYPE` as follows\n",
    "- Lower secondary -> 1\n",
    "- Secondary / secondary special -> 2\n",
    "- Incomplete higher -> 3\n",
    "- Higher education -> 4\n",
    "\n",
    "\n",
    "(Total: 5 marks)  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_size_mapping = {'Lower secondary':1, 'Secondary / secondary special':2, 'Incomplete higher':3, 'Higher education':4}\n",
    "\n",
    "df_final['NAME_EDUCATION_TYPE'] = df_final['NAME_EDUCATION_TYPE'].map(new_size_mapping)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<hr style=\"width:25%;margin-left:0;\"> \n",
    "\n",
    "**Question 6**. \n",
    "\n",
    "Add dummy variables to `df_final` for all of the nominal features which are currently stored as string (text). \n",
    "- Make sure to delete the original variables from the dataframe\n",
    "- Drop the first column from each set of created dummy variable, i.e. for each feature\n",
    "\n",
    "\n",
    "\n",
    "(Total: 10 marks)  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "\"None of [Index(['colour'], dtype='object')] are in the [columns]\"",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-37-ac367da9f7b6>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0mdf_final\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m \u001b[0mone_hot\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_dummies\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdf_final\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'colour'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      5\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mone_hot\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.8/site-packages/pandas/core/frame.py\u001b[0m in \u001b[0;36m__getitem__\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m   3028\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mis_iterator\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3029\u001b[0m                 \u001b[0mkey\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3030\u001b[0;31m             \u001b[0mindexer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mloc\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_get_listlike_indexer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mraise_missing\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   3031\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3032\u001b[0m         \u001b[0;31m# take() does not accept boolean indexers\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.8/site-packages/pandas/core/indexing.py\u001b[0m in \u001b[0;36m_get_listlike_indexer\u001b[0;34m(self, key, axis, raise_missing)\u001b[0m\n\u001b[1;32m   1264\u001b[0m             \u001b[0mkeyarr\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mindexer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnew_indexer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0max\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_reindex_non_unique\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkeyarr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1265\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1266\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_validate_read_indexer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkeyarr\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mindexer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mraise_missing\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mraise_missing\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1267\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mkeyarr\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mindexer\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1268\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.8/site-packages/pandas/core/indexing.py\u001b[0m in \u001b[0;36m_validate_read_indexer\u001b[0;34m(self, key, indexer, axis, raise_missing)\u001b[0m\n\u001b[1;32m   1306\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mmissing\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mindexer\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1307\u001b[0m                 \u001b[0maxis_name\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mobj\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_get_axis_name\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0maxis\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1308\u001b[0;31m                 \u001b[0;32mraise\u001b[0m \u001b[0mKeyError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf\"None of [{key}] are in the [{axis_name}]\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1309\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1310\u001b[0m             \u001b[0max\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mobj\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_get_axis\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0maxis\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyError\u001b[0m: \"None of [Index(['colour'], dtype='object')] are in the [columns]\""
     ]
    }
   ],
   "source": [
    "pd.set_option(\"display.max_rows\", None, \"display.max_columns\", None, \"display.width\", None) # pretty printing\n",
    "df_final\n",
    "\n",
    "one_hot = pd.get_dummies(df_final[['colour']])\n",
    "print(one_hot)\n",
    "\n",
    "df_final = df_final.join(one_hot)\n",
    "df_final\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_final['NAME_INCOME_TYPE'].unique()\n",
    "\n",
    "Map_Name = {'Working':10, 'Commercial associate':11, 'Pensioner':12, 'State servant':13,\n",
    "       'Student':14}#???? maybe\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "---\n",
    "\n",
    "### Task 3 Preparing X and y arrays (Total Marks: 10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Question 7**. \n",
    "\n",
    "- Create a numpy array named `y` from the `y` column of `df_final` making sure that the values of the array `y` are stored as integers (3 marks)   \n",
    "- Create a numpy array named `X`  from all the remaining features in `df_final` (2 marks)   \n",
    "\n",
    "(Total: 5 Marks)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "y = np.ravel(df_final['y'])\n",
    "X = df_final[['CNT_CHILDREN', 'AMT_INCOME_TOTAL', 'DAYS_BIRTH', 'DAYS_EMPLOYED', 'FLAG_MOBIL', 'FLAG_WORK_PHONE', 'FLAG_PHONE', 'FLAG_EMAIL', 'OCCUPATION_TYPE', 'CNT_FAM_MEMBERS' , 'CODE_GENDER', 'FLAG_OWN_CAR', 'FLAG_OWN_REALTY', 'NAME_INCOME_TYPE', 'NAME_FAMILY_STATUS', 'NAME_HOUSING_TYPE' ]].values\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<hr style=\"width:25%;margin-left:0;\"> \n",
    "\n",
    "**Question 8**. \n",
    "\n",
    "- Use an appropriate scikit-learn library we used in class to create `y_train`, `y_test`, `X_train` and `X_test` by splitting the data into 70% train and 30% test datasets (2.5 marks) \n",
    "    - Set random_state to 7 and stratify the subsamples so that train and test datasets have roughly equal proportions of the target's class labels \n",
    "- Standardise the data using `StandardScaler` library (2.5 marks)   \n",
    "\n",
    "(Total: 5 marks) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.3, random_state = 7, stratify = y)\n",
    "# print(X_train.shape)\n",
    "# print(y_train.shape)\n",
    "# print(X_test.shape)\n",
    "# print(y_test.shape)\n",
    "# print(y_train)\n",
    "# print(y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "could not convert string to float: 'Core staff'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-42-72700d9d2c06>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0msc\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mStandardScaler\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m \u001b[0msc\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      5\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0;31m# print(dir(sc))\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.8/site-packages/sklearn/preprocessing/_data.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, X, y, sample_weight)\u001b[0m\n\u001b[1;32m    728\u001b[0m         \u001b[0;31m# Reset internal state before fitting\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    729\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_reset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 730\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpartial_fit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msample_weight\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    731\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    732\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mpartial_fit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msample_weight\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.8/site-packages/sklearn/preprocessing/_data.py\u001b[0m in \u001b[0;36mpartial_fit\u001b[0;34m(self, X, y, sample_weight)\u001b[0m\n\u001b[1;32m    764\u001b[0m         \"\"\"\n\u001b[1;32m    765\u001b[0m         \u001b[0mfirst_call\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mhasattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"n_samples_seen_\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 766\u001b[0;31m         X = self._validate_data(X, accept_sparse=('csr', 'csc'),\n\u001b[0m\u001b[1;32m    767\u001b[0m                                 \u001b[0mestimator\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mFLOAT_DTYPES\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    768\u001b[0m                                 force_all_finite='allow-nan', reset=first_call)\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.8/site-packages/sklearn/base.py\u001b[0m in \u001b[0;36m_validate_data\u001b[0;34m(self, X, y, reset, validate_separately, **check_params)\u001b[0m\n\u001b[1;32m    419\u001b[0m             \u001b[0mout\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mX\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    420\u001b[0m         \u001b[0;32melif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0my\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m'no_validation'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 421\u001b[0;31m             \u001b[0mX\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcheck_array\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mcheck_params\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    422\u001b[0m             \u001b[0mout\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mX\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    423\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.8/site-packages/sklearn/utils/validation.py\u001b[0m in \u001b[0;36minner_f\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     61\u001b[0m             \u001b[0mextra_args\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mall_args\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     62\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mextra_args\u001b[0m \u001b[0;34m<=\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 63\u001b[0;31m                 \u001b[0;32mreturn\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     64\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     65\u001b[0m             \u001b[0;31m# extra_args > 0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.8/site-packages/sklearn/utils/validation.py\u001b[0m in \u001b[0;36mcheck_array\u001b[0;34m(array, accept_sparse, accept_large_sparse, dtype, order, copy, force_all_finite, ensure_2d, allow_nd, ensure_min_samples, ensure_min_features, estimator)\u001b[0m\n\u001b[1;32m    614\u001b[0m                     \u001b[0marray\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0marray\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mastype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcasting\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"unsafe\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcopy\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    615\u001b[0m                 \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 616\u001b[0;31m                     \u001b[0marray\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0masarray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0morder\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0morder\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    617\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0mComplexWarning\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mcomplex_warning\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    618\u001b[0m                 raise ValueError(\"Complex data not supported\\n\"\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.8/site-packages/numpy/core/_asarray.py\u001b[0m in \u001b[0;36masarray\u001b[0;34m(a, dtype, order, like)\u001b[0m\n\u001b[1;32m    100\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0m_asarray_with_like\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ma\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0morder\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0morder\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlike\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mlike\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    101\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 102\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0marray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ma\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcopy\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0morder\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0morder\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    103\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    104\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: could not convert string to float: 'Core staff'"
     ]
    }
   ],
   "source": [
    "np.set_printoptions(precision=3, suppress = True) \n",
    "sc = StandardScaler()\n",
    "\n",
    "sc.fit(X_train)\n",
    "\n",
    "# print(dir(sc))\n",
    "# print(sc.mean_, sc.scale_)\n",
    "\n",
    "\n",
    "X_train_scaled = sc.transform(X_train)\n",
    "# print('means:', X_train.mean(axis=0), X_train_scaled.mean(axis=0))\n",
    "# print('sigmas', X_train.std(axis=0), X_train_scaled.std(axis=0))\n",
    "\n",
    "X_test_scaled = sc.transform(X_test)\n",
    "# print('means:', X_test.mean(axis=0), X_test_scaled.mean(axis=0))\n",
    "# print('sigmas', X_test.std(axis=0), X_test_scaled.std(axis=0))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "---\n",
    "\n",
    "### Task 4. Support Vector Classifier and Accuracies (Total Marks: 30)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Question 9**. \n",
    "\n",
    "- Train a Support Vector Classifier on standardised data (3 marks)\n",
    "    - Use `linear` kernel and set `random_state` to 7 (don't change any other parameters)\n",
    "    - Compute and print training and test dataset accuracies\n",
    "- Train another Support Vector Classifier on standardised data (3 marks)\n",
    "    - Use `rbf` kernel and set `random_state` to 7 (don't change any other parameters)\n",
    "    - Compute and print training and test dataset accuracies\n",
    "- What can you say about the presence of nonlinearities in the dataset? (4 marks)\n",
    "\n",
    "(Total: 10 marks)  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#--------------  1.\n",
    "lda = LDA(n_components = 2)\n",
    "X_train_lda = lda.fit_transform(X_train_scaled, y_train)\n",
    "pd.DataFrame(X_train_lda)\n",
    "#--------------  2.  \n",
    "lr = LogisticRegression(multi_class='ovr', random_state=1)\n",
    "lr.fit(X_train_lda, y_train)\n",
    "#--------------  3.  \n",
    "print('Accuracy - Training:', lr.score(X_train_lda, y_train))\n",
    "pdr.plot_decision_regions(X_train_lda, y_train, classifier=lr)\n",
    "plt.xlabel('LD 1')\n",
    "plt.ylabel('LD 2')\n",
    "plt.legend(loc='lower left')\n",
    "plt.tight_layout()\n",
    "plt.show() \n",
    "#--------------  4.  \n",
    "X_test_lda = lda.transform(X_test_scaled)\n",
    "print('Accuracy - Training:', lr.score(X_test_lda, y_test))\n",
    "\n",
    "pdr.plot_decision_regions(X_test_lda, y_test, classifier=lr)\n",
    "plt.xlabel('LD 1')\n",
    "plt.ylabel('LD 2')\n",
    "plt.legend(loc='lower left')\n",
    "plt.tight_layout()\n",
    "# plt.savefig('images/05_10.png', dpi=300)\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---- provide your text answer here ----"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<hr style=\"width:25%;margin-left:0;\"> \n",
    "\n",
    "**Question 10**\n",
    "\n",
    "- Extract 2 linear principal components from the standardised features using an appropriate `sklearn` library (5 marks)\n",
    "- Train a Support Vector Classifier on the computed principal components (5 marks) \n",
    "    - Use `rbf` kernel and set `random_state` to 7 (don't change any other parameters)\n",
    "- Compute and print training and test dataset accuracies (5 marks)\n",
    "- What can you say about the ability of the 2 principal components to compress the information contained in the features matrix `X`, and why? (5 marks)     \n",
    "\n",
    "\n",
    "(Total: 20 marks)  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.decomposition import KernelPCA\n",
    "kpca = KernelPCA(n_components=2, kernel='rbf', gamma=15)\n",
    "X_kpca = kpca.fit_transform(X)\n",
    "\n",
    "plt.scatter(X_kpca[y==0, 0], X_kpca[y==0, 1], color='red', marker='^', alpha=0.5)\n",
    "plt.scatter(X_kpca[y==1, 0], X_kpca[y==1, 1], color='blue', marker='o', alpha=0.5)\n",
    "plt.xlabel('K-PC1')\n",
    "plt.ylabel('K-PC2')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---- provide your text answer here ----\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "---"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
